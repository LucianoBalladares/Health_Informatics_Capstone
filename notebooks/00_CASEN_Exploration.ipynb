{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d64e02",
   "metadata": {},
   "source": [
    "# CASEN 2017–2022 Data Exploration\n",
    "Objective: Inspect variables, confirm structure, and select features for regional aggregation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a05154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8aa250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASEN 2022 existe: True\n",
      "Factor CASEN 2017 existe: True\n"
     ]
    }
   ],
   "source": [
    "# Relative Paths\n",
    "path_casen_2022 = \"../data/raw/Base de datos Casen 2022 STATA_18 marzo 2024.dta\"\n",
    "path_casen_2017_factor = \"../data/raw/Casen2017_factorCenso2017.dta\"\n",
    "\n",
    "# Verify\n",
    "print(\"CASEN 2022 existe:\", os.path.exists(path_casen_2022))\n",
    "print(\"Factor CASEN 2017 existe:\", os.path.exists(path_casen_2017_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a03f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3502/4044336951.py:15: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  casen_2022_sample = reader_2022.get_chunk(5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CASEN 2022 SAMPLE ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Columns: 918 entries, id_vivienda to allega_int\n",
      "dtypes: datetime64[ns](1), float64(603), int16(9), int32(120), int8(152), object(33)\n",
      "memory usage: 27.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_vivienda</th>\n",
       "      <th>folio</th>\n",
       "      <th>id_persona</th>\n",
       "      <th>region</th>\n",
       "      <th>area</th>\n",
       "      <th>cod_upm</th>\n",
       "      <th>nse</th>\n",
       "      <th>estrato</th>\n",
       "      <th>hogar</th>\n",
       "      <th>expr</th>\n",
       "      <th>expr_osig</th>\n",
       "      <th>varstrat</th>\n",
       "      <th>varunit</th>\n",
       "      <th>fecha_entrev</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>tot_per_h</th>\n",
       "      <th>h1</th>\n",
       "      <th>edad</th>\n",
       "      <th>mes_nac_nna</th>\n",
       "      <th>...</th>\n",
       "      <th>asiste</th>\n",
       "      <th>educ</th>\n",
       "      <th>depen</th>\n",
       "      <th>activ</th>\n",
       "      <th>asal</th>\n",
       "      <th>contrato</th>\n",
       "      <th>cotiza</th>\n",
       "      <th>lugar_nac</th>\n",
       "      <th>pueblos_indigenas</th>\n",
       "      <th>n_ocupados</th>\n",
       "      <th>n_desocupados</th>\n",
       "      <th>n_inactivos</th>\n",
       "      <th>conyuge_jh</th>\n",
       "      <th>numper</th>\n",
       "      <th>numnuc</th>\n",
       "      <th>men18c</th>\n",
       "      <th>may60c</th>\n",
       "      <th>tipohogar</th>\n",
       "      <th>tot_hog</th>\n",
       "      <th>ind_hacina</th>\n",
       "      <th>indsan</th>\n",
       "      <th>ten_viv</th>\n",
       "      <th>ten_viv_f</th>\n",
       "      <th>allega_ext</th>\n",
       "      <th>allega_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000901</td>\n",
       "      <td>100090101</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10009</td>\n",
       "      <td>4</td>\n",
       "      <td>1630324</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>54.0</td>\n",
       "      <td>751</td>\n",
       "      <td>12041</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000901</td>\n",
       "      <td>100090101</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10009</td>\n",
       "      <td>4</td>\n",
       "      <td>1630324</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751</td>\n",
       "      <td>12041</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000901</td>\n",
       "      <td>100090101</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10009</td>\n",
       "      <td>4</td>\n",
       "      <td>1630324</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>122.0</td>\n",
       "      <td>751</td>\n",
       "      <td>12041</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000902</td>\n",
       "      <td>100090201</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10009</td>\n",
       "      <td>4</td>\n",
       "      <td>1630324</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751</td>\n",
       "      <td>12041</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000902</td>\n",
       "      <td>100090201</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10009</td>\n",
       "      <td>4</td>\n",
       "      <td>1630324</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>131.0</td>\n",
       "      <td>751</td>\n",
       "      <td>12041</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_vivienda      folio  id_persona  region  area  cod_upm  nse  estrato  hogar  expr  expr_osig  varstrat  varunit  \\\n",
       "0      1000901  100090101           1      16     2    10009    4  1630324      1    43       54.0       751    12041   \n",
       "1      1000901  100090101           2      16     2    10009    4  1630324      1    43        NaN       751    12041   \n",
       "2      1000901  100090101           3      16     2    10009    4  1630324      1    44      122.0       751    12041   \n",
       "3      1000902  100090201           1      16     2    10009    4  1630324      1    51        NaN       751    12041   \n",
       "4      1000902  100090201           2      16     2    10009    4  1630324      1    51      131.0       751    12041   \n",
       "\n",
       "  fecha_entrev  p1  p2  p3  p4  p9  p10  p11  tot_per_h  h1  edad  mes_nac_nna  ...  asiste  educ  depen  activ  asal  \\\n",
       "0   2023-01-28   1   2   4   4   3  1.0  NaN          3   1    72          NaN  ...       2     1    NaN    3.0   NaN   \n",
       "1   2023-01-28   1   2   4   4   3  1.0  NaN          3   1    67          NaN  ...       2     1    NaN    1.0   0.0   \n",
       "2   2023-01-28   1   2   4   4   3  1.0  NaN          3   1    40          NaN  ...       2     8    NaN    1.0   1.0   \n",
       "3   2022-12-29   1   2   4   4   4  1.0  NaN          4   1    56          NaN  ...       2   -88    NaN    3.0   NaN   \n",
       "4   2022-12-29   1   2   4   4   4  1.0  NaN          4   1    25          NaN  ...       2     5    NaN    3.0   NaN   \n",
       "\n",
       "   contrato  cotiza  lugar_nac  pueblos_indigenas  n_ocupados  n_desocupados  n_inactivos  conyuge_jh  numper  numnuc  \\\n",
       "0       NaN     0.0          0                  0           2              0            1           1       3       1   \n",
       "1       NaN     1.0          0                  0           2              0            1           1       3       1   \n",
       "2     -88.0     1.0          0                  0           2              0            1           1       3       1   \n",
       "3       NaN     0.0          0                  0           0              0            3           1       4       2   \n",
       "4       NaN     1.0          0                  0           0              0            3           1       4       2   \n",
       "\n",
       "   men18c  may60c  tipohogar  tot_hog  ind_hacina  indsan  ten_viv  ten_viv_f  allega_ext  allega_int  \n",
       "0       0       1          3        1           1       1        1          1           0           0  \n",
       "1       0       1          3        1           1       1        1          1           0           0  \n",
       "2       0       1          3        1           1       1        1          1           0           0  \n",
       "3       1       1          5        1           1       2        1          1           0           1  \n",
       "4       1       1          5        1           1       2        1          1           0           1  \n",
       "\n",
       "[5 rows x 918 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FACTOR CASEN 2017 SAMPLE ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   folio       5000 non-null   float64\n",
      " 1   o           5000 non-null   int8   \n",
      " 2   expr_C2017  5000 non-null   float32\n",
      "dtypes: float32(1), float64(1), int8(1)\n",
      "memory usage: 63.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folio</th>\n",
       "      <th>o</th>\n",
       "      <th>expr_C2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.101100e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.101100e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.101100e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.101100e+11</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101100e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          folio  o  expr_C2017\n",
       "0  1.101100e+11  1        39.0\n",
       "1  1.101100e+11  1        39.0\n",
       "2  1.101100e+11  1        39.0\n",
       "3  1.101100e+11  2        39.0\n",
       "4  1.101100e+11  1        39.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterative read to avoid crushing\n",
    "reader_2022 = pd.read_stata(\n",
    "    path_casen_2022,\n",
    "    iterator=True,\n",
    "    convert_categoricals=False\n",
    ")\n",
    "\n",
    "reader_2017 = pd.read_stata(\n",
    "    path_casen_2017_factor,\n",
    "    iterator=True,\n",
    "    convert_categoricals=False\n",
    ")\n",
    "\n",
    "# 5K sample\n",
    "casen_2022_sample = reader_2022.get_chunk(5000)\n",
    "casen_2017_sample = reader_2017.get_chunk(5000)\n",
    "\n",
    "print(\"=== CASEN 2022 SAMPLE ===\")\n",
    "casen_2022_sample.info()\n",
    "display(casen_2022_sample.head())\n",
    "\n",
    "print(\"\\n=== FACTOR CASEN 2017 SAMPLE ===\")\n",
    "casen_2017_sample.info()\n",
    "display(casen_2017_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8369367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columnas CASEN 2022: 918\n",
      "\n",
      "Primeras 50 columnas:\n",
      "['id_vivienda', 'folio', 'id_persona', 'region', 'area', 'cod_upm', 'nse', 'estrato', 'hogar', 'expr', 'expr_osig', 'varstrat', 'varunit', 'fecha_entrev', 'p1', 'p2', 'p3', 'p4', 'p9', 'p10', 'p11', 'tot_per_h', 'h1', 'edad', 'mes_nac_nna', 'ano_nac_nna', 'sexo', 'pco1_a', 'pco1_b', 'pco1', 'h5_cp', 'h5_sp', 'h5_b1_1', 'h5_b1_2', 'h5a_2', 'h5_b2_1', 'h5_b2_2', 'h5a_3', 'h5_b3_1', 'h5_b3_2', 'h5a_4', 'h5b', 'ecivil', 'h5_10', 'h5_1a', 'h5_1b', 'h5_20', 'h5_2', 'n_nucleos', 'nucleo']\n",
      "\n",
      "Patrón: 'region' → 1 columnas encontradas\n",
      "['region']\n",
      "\n",
      "Patrón: 'reg' → 61 columnas encontradas\n",
      "['region', 'e6d_preg', 'y3a_preg', 'y3b_preg', 'y3c_preg', 'y3d_preg', 'y3e_preg', 'y3f_preg', 'y4a_preg', 'y4b_preg', 'y4c_preg', 'y4d_preg', 'y5a_preg', 'y5b_preg', 'y5c_preg', 'y5d_preg', 'y5e_preg', 'y5f_preg', 'y5g_preg', 'y5h_preg', 'y5i_preg', 'y5j_preg', 'y5k_preg', 'y5l_preg', 'y11_preg', 'y12a_preg', 'y12b_preg', 'y13a_preg', 'y13b_preg', 'y13c_preg']\n",
      "\n",
      "Patrón: 'comuna' → 4 columnas encontradas\n",
      "['r1b_comuna_esp', 'r1b_comuna_esp_cod', 'r2_comuna_esp', 'r2_comuna_esp_cod']\n",
      "\n",
      "Patrón: 'com' → 6 columnas encontradas\n",
      "['e6c_completo', 'e9com_cod', 'r1b_comuna_esp', 'r1b_comuna_esp_cod', 'r2_comuna_esp', 'r2_comuna_esp_cod']\n",
      "\n",
      "Patrón: 'exp' → 2 columnas encontradas\n",
      "['expr', 'expr_osig']\n",
      "\n",
      "Patrón: 'expr' → 2 columnas encontradas\n",
      "['expr', 'expr_osig']\n",
      "\n",
      "Patrón: 'pobr' → 3 columnas encontradas\n",
      "['pobreza', 'pobreza_multi_5d', 'pobreza_multi_4d']\n",
      "\n",
      "Patrón: 'pobre' → 3 columnas encontradas\n",
      "['pobreza', 'pobreza_multi_5d', 'pobreza_multi_4d']\n",
      "\n",
      "Patrón: 'ing' → 0 columnas encontradas\n",
      "[]\n",
      "\n",
      "Patrón: 'educ' → 1 columnas encontradas\n",
      "['educ']\n",
      "\n",
      "Patrón: 'edad' → 1 columnas encontradas\n",
      "['edad']\n",
      "\n",
      "Patrón: 'hog' → 4 columnas encontradas\n",
      "['hogar', 'y26d_hog', 'tipohogar', 'tot_hog']\n",
      "\n",
      "Patrón: 'tam' → 0 columnas encontradas\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cols = casen_2022_sample.columns.tolist()\n",
    "\n",
    "print(\"Total columnas CASEN 2022:\", len(cols))\n",
    "print(\"\\nPrimeras 50 columnas:\")\n",
    "print(cols[:50])\n",
    "\n",
    "patterns = [\"region\", \"reg\", \"comuna\", \"com\", \"exp\", \"expr\", \"pobr\", \"pobre\", \"ing\", \"educ\", \"edad\", \"hog\", \"tam\"]\n",
    "\n",
    "for p in patterns:\n",
    "    matches = [c for c in cols if p in c.lower()]\n",
    "    print(f\"\\nPatrón: '{p}' → {len(matches)} columnas encontradas\")\n",
    "    print(matches[:30])  # show 30 to avoid saturation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b8ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibles variables de ingreso (primeras 50):\n",
      "['y1', 'y2_dias', 'y2_hrs', 'y3a_preg', 'y3b_preg', 'y3c_preg', 'y3d_preg', 'y3e_preg', 'y3f_preg', 'y3a', 'y3ap', 'y3b', 'y3bp', 'y3c', 'y3cp', 'y3d', 'y3dp', 'y3e', 'y3ep', 'y3f_esp', 'y3f', 'y3fp', 'y4a_preg', 'y4b_preg', 'y4c_preg', 'y4d_preg', 'y4a', 'y4b', 'y4c', 'y4d_esp', 'y4d', 'y5a_preg', 'y5b_preg', 'y5c_preg', 'y5d_preg', 'y5e_preg', 'y5f_preg', 'y5g_preg', 'y5h_preg', 'y5i_preg', 'y5j_preg', 'y5k_preg', 'y5l_preg', 'y5a', 'y5b', 'y5c', 'y5d', 'y5e', 'y5f', 'y5g']\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar variables de ingreso/candidatas (ajusta el patrón si quieres afinar)\n",
    "income_candidates = [c for c in casen_2022_sample.columns \n",
    "                     if \"ing\" in c.lower() or \"y\" in c.lower()]\n",
    "\n",
    "print(\"Posibles variables de ingreso (primeras 50):\")\n",
    "print(income_candidates[:50])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
